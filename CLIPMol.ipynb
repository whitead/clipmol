{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CLIP Mol",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFxgLV5HAEEw"
      },
      "source": [
        "# CLIP Mol\n",
        "\n",
        "Make molecules that look like a given text prompt. This was built using [SELFIES](https://github.com/aspuru-guzik-group/selfies) to generate the molecules, [rdkit](https://www.rdkit.org/) to draw the molecules, [CLIP](https://github.com/openai/CLIP) to compare the images to the text prompt, and [pymoo](https://pymoo.org) to optimize the molecules' agreement with CLIP. \n",
        "\n",
        "Here are some examples:\n",
        "\n",
        "### Bird\n",
        "![Molecule that looks like a bird](https://raw.githubusercontent.com/whitead/clipmol/main/examples/bird.png)\n",
        "\n",
        "### Cat\n",
        "![Molecule that looks like a cat](https://raw.githubusercontent.com/whitead/clipmol/main/examples/cat.png)\n",
        "\n",
        "\n",
        "### Fir Tree Animation\n",
        "<details>\n",
        "<summary>Click to shiow</summary>\n",
        "\n",
        "![Time laps of molecule turning into a fir tree](https://raw.githubusercontent.com/whitead/clipmol/main/examples/christmas.gif)\n",
        "\n",
        "</details>\n",
        "\n",
        "## FAQ\n",
        "\n",
        "[See FAQ](https://github.com/whitead/clipmol#faq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMc1AXzBlhzm",
        "collapsed": true,
        "cellView": "form"
      },
      "source": [
        "#@title Install and Load Packages\n",
        "#@markdown Exectue this cell to load packages\n",
        "\n",
        "!pip install ftfy regex tqdm rdkit-pypi pymoo selfies\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!apt install imagemagick\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from collections import OrderedDict\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from IPython.display import SVG\n",
        "import selfies as sf\n",
        "from IPython.display import display\n",
        "from rdkit.DataStructs.cDataStructs import TanimotoSimilarity\n",
        "import rdkit.Chem.rdMolDescriptors\n",
        "from rdkit.Chem.Draw import rdDepictor\n",
        "import json\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "import torch\n",
        "import clip\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "IPythonConsole.ipython_useSVG = True\n",
        "%matplotlib inline\n",
        "\n",
        "# load clip model\n",
        "\n",
        "model, preprocess = clip.load('ViT-B/32')\n",
        "model.cuda().eval()\n",
        "input_resolution = model.visual.input_resolution\n",
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size\n",
        "\n",
        "def draw(smiles, dos):\n",
        "  return np.stack([\n",
        "                   preprocess(Chem.Draw.MolToImage(Chem.MolFromSmiles(s), size=(input_resolution, input_resolution), options=dos).convert('RGB')) for s in smiles])\n",
        "def score(smiles, text_features, dos):\n",
        "  image_input = torch.tensor(draw(smiles, dos)).cuda()\n",
        "  with torch.no_grad():\n",
        "    image_features = model.encode_image(image_input).float()\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    t = text_features.cpu().numpy()\n",
        "    i = image_features.cpu().numpy()\n",
        "    similarity =  t[0] @ i.T\n",
        "    return -similarity\n",
        "    \n",
        "def similarity(smiles, ref):\n",
        "    mol_list = [Chem.MolFromSmiles(x) for x in smiles]\n",
        "    fps = [ rdkit.Chem.rdMolDescriptors.GetMorganFingerprintAsBitVect(x,2) for x in mol_list]\n",
        "    fpr = rdkit.Chem.rdMolDescriptors.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(ref),2)\n",
        "    return np.array([TanimotoSimilarity(f,fpr) for f in fps])\n",
        "\n",
        "# used to get token counts\n",
        "if False:\n",
        "  # make alphabet with oversampling in important tokens\n",
        "  data_url = \"https://github.com/aspuru-guzik-group/selfies/raw/16a489afa70882428bc194b2b24a2d33573f1651/examples/vae_example/datasets/dataJ_250k_rndm_zinc_drugs_clean.txt\"\n",
        "  pd_data = pd.read_csv(data_url)\n",
        "  selfies_list = [sf.encoder(s) for s in pd_data.iloc[:, 0]]\n",
        "\n",
        "  selfies_symbol_counts = {\"[nop]\": 0}\n",
        "\n",
        "\n",
        "  def parse(s):\n",
        "      for si in s.split(\"[\")[1:]:\n",
        "          token = \"[\" + si\n",
        "          if token in selfies_symbol_counts:\n",
        "              selfies_symbol_counts[token] += 1\n",
        "          else:\n",
        "              selfies_symbol_counts[token] = 0\n",
        "\n",
        "\n",
        "  [parse(s) for s in selfies_list]\n",
        "  sorted_token_counts = list(sorted(selfies_symbol_counts.items(), key=lambda i: -i[1]))\n",
        "  for p in sorted_token_counts[:10]:\n",
        "      print(*p)\n",
        "  # print out topic tokens\n",
        "  with open('tokens.json', 'r') as f:\n",
        "    f.write(json.dumps(sorted_token_counts))\n",
        "  files.download('tokens.json') \n",
        "\n",
        "# load tokens\n",
        "url = \"https://raw.githubusercontent.com/whitead/clipmol/main/tokens.json\"\n",
        "sorted_token_counts = json.loads(urlopen(url).read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3IfrCkZwc1-",
        "cellView": "form"
      },
      "source": [
        "\n",
        "#@title Run CLIP Mol\n",
        "\n",
        "\n",
        "prompt = \"A symmetric fir tree\" #@param {type:\"string\"}\n",
        "random_seed =  2#@param\n",
        "mol_drawer = \"rdkit\" #@param [\"rdkit\", \"CoordGen\"]\n",
        "black_and_white = True #@param\n",
        "#@markdown *whether to consider color when computing agreement with prompt*\n",
        "iterations = 500 #@param\n",
        "mol_diversity = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown *1 = only carbon, increase to add more types of elements/bonds*\n",
        "mol_size = 100 #@param {type:\"slider\", min:30, max:300, step:10}\n",
        "\n",
        "#@markdown *molecule size is number of SELFIES tokens, not number of atoms*\n",
        "\n",
        "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
        "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
        "import pymoo.factory\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.visualization.scatter import Scatter\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.core.callback import Callback\n",
        "from pymoo.core.evaluator import Evaluator\n",
        "from pymoo.core.population import Population\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "#set-up alphabet\n",
        "# downselect to top M and repeat to fill up to N according to ratios\n",
        "M = mol_diversity + 5\n",
        "N = max(M, 30)\n",
        "alphabet = list([t[0] for t in sorted_token_counts[:M]])\n",
        "sum_counts = sum([t[1] for t in sorted_token_counts[:M]])\n",
        "# now fill in with repeats of most common\n",
        "for t,c in sorted_token_counts[:M]:\n",
        "  i = int(c / sum_counts * (N - M))\n",
        "  alphabet += [t] * i\n",
        "alphabet.sort()\n",
        "alphabet.insert(0, '[nop]')\n",
        "\n",
        " # carbon only?\n",
        "if mol_diversity == 1:\n",
        "  alphabet = ['[nop]', '[C]', '[Ring1]', '[Branch1]', '[Branch2]', '[Ring2]']\n",
        "vocab_itos = {i: s for i, s in enumerate(alphabet)}\n",
        "\n",
        "def ints2smiles(ints):\n",
        "  selfies = sf.encoding_to_selfies(ints, vocab_itos, 'label')\n",
        "  return sf.decoder(selfies)\n",
        "\n",
        "class CLIPMol(Problem):\n",
        "    def __init__(self, L, text, black_white=True):\n",
        "        super().__init__(n_var=L, n_obj=3, n_constr=0, xl=[0] * L, xu=[len(alphabet) - 1] * L)\n",
        "        text_tokens = clip.tokenize([text]).cuda()\n",
        "        self.L = L\n",
        "        self.dos = Chem.Draw.MolDrawOptions()\n",
        "        if black_white:\n",
        "          self.dos.useBWAtomPalette()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          self.text_features = model.encode_text(text_tokens).float()\n",
        "        self.text_features /= self.text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        s = [ints2smiles(xi) for xi in x]\n",
        "        scores = score(s, self.text_features, dos=self.dos)\n",
        "        i = np.argmin(scores)\n",
        "        lengths = [max(-50, -len(si)) for si in s]\n",
        "        d = similarity(s, s[i])\n",
        "        F = np.column_stack((d, lengths, scores))\n",
        "        out[\"F\"] = F\n",
        "class DrawCallback(Callback):\n",
        "\n",
        "    def __init__(self, period=10, display=9) -> None:\n",
        "        super().__init__()\n",
        "        self.calls = 0  \n",
        "        self.period = period\n",
        "        self.results = []\n",
        "        self.display = display\n",
        "        self.scores = []\n",
        "\n",
        "    def notify(self, algorithm):\n",
        "        self.calls += 1\n",
        "        l = np.argmin(algorithm.pop.get(\"F\")[:, -1])\n",
        "        best = ints2smiles(algorithm.pop.get(\"X\")[l])\n",
        "        self.results.append(best)\n",
        "        self.scores.append(algorithm.pop.get(\"F\")[l, -1])\n",
        "        if self.calls % self.period == 0:\n",
        "          i = np.argsort(algorithm.pop.get(\"F\")[:,-1])\n",
        "          # downsample\n",
        "          stride = len(algorithm.pop) // self.display\n",
        "          i = i[:self.display * stride:stride]\n",
        "          mols = [Chem.MolFromSmiles(ints2smiles(s)) for s in algorithm.pop.get(\"X\")[i]]\n",
        "          clear_output(wait=True)\n",
        "          display('Iteration {} / {}'.format(self.calls, iterations))\n",
        "          display(Draw.MolsToGridImage(mols, molsPerRow=3, useSVG=True, \n",
        "                               legends = ['Similarity: {:.3f}'.format(-s) for s in algorithm.pop.get(\"F\")[i, -1]],\n",
        "                               subImgSize=(input_resolution, input_resolution), ))\n",
        "          \n",
        "# fancy coordinates slow but increases diversity and is usually worse\n",
        "rdDepictor.SetPreferCoordGen(False if mol_drawer == 'rdkit' else True)\n",
        "my_problem = CLIPMol(mol_size, prompt, black_and_white)\n",
        "c = DrawCallback(10)\n",
        "pop_size = 150 if mol_drawer == 'rdkit' else 50\n",
        "\n",
        "algorithm = NSGA2(pop_size=pop_size,\n",
        "                  sampling=pymoo.factory.get_sampling(\"int_random\"),\n",
        "                  #crossover=pymoo.factory.get_crossover(\"int_sbx\",eta=N / M * 3),\n",
        "                  crossover=pymoo.factory.get_crossover(\"int_exp\"),\n",
        "                  mutation=pymoo.factory.get_mutation(\"int_pm\", eta=N / M * 3))\n",
        "\n",
        "res = minimize(my_problem,\n",
        "               algorithm,\n",
        "               ('n_gen', iterations),\n",
        "               seed=random_seed,\n",
        "               callback=c,\n",
        "               verbose=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ACO3G9f2-H0",
        "cellView": "form"
      },
      "source": [
        "#@title Save Output Image\n",
        "\n",
        "import os, glob\n",
        "\n",
        "for f in glob.glob('*.png'):\n",
        "  os.remove(f)\n",
        "\n",
        "dos = Chem.Draw.MolDrawOptions()\n",
        "if black_and_white:\n",
        "  dos.useBWAtomPalette()\n",
        "\n",
        "last = ''\n",
        "index = 0\n",
        "for s, r in zip(c.scores, c.results):\n",
        "  if r != last:\n",
        "    f = '{:03d}.png'.format(index)\n",
        "    m = Chem.Draw.MolToImage(Chem.MolFromSmiles(r), size=(512, 512), options=dos, legend=prompt + '\\n\\nScore: {:.3f}'.format(-s))\n",
        "    m.save(f)\n",
        "    index += 1\n",
        "  last = r\n",
        "f = '{:03d}.png'.format(index)\n",
        "r = c.results[np.argmin(c.scores)]\n",
        "m = Chem.Draw.MolToImage(Chem.MolFromSmiles(r), size=(512, 512), options=dos, legend=prompt + '\\n\\nScore: {:.3f}'.format(-s))\n",
        "m.save(f)\n",
        "files.download(f) \n",
        "print(r)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save GIF of Search\n",
        "!convert -delay 25 -loop 1 *.png mol.gif\n",
        "files.download('mol.gif') "
      ],
      "metadata": {
        "cellView": "form",
        "id": "v6CKjGiCMydb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVolz0XP3RyN",
        "cellView": "form"
      },
      "source": [
        "#@title ZINC\n",
        "#@markdown This searches through commercially available molecules in [ZINC20](https://zinc20.docking.org) to find a molecule that matches the prompt.\n",
        "#@markdown *ZINC20 is usually overloaded, so this code may only run sometimes.*\n",
        "tranches = pd.read_csv('https://gist.githubusercontent.com/whitead/f47887e45bbd2f38332182d2d422da6b/raw/a3948beac9b9034dab432b697c5ec238503ac5d0/tranches.txt')\n",
        "def get_mol_batch(batch_size = 32):\n",
        "  for t in tranches.values:\n",
        "    print('On tranch', t[0])\n",
        "    d = pd.read_csv(t[0], sep=' ')    \n",
        "    for i in range(len(d) // batch_size):\n",
        "      yield d.iloc[i * batch_size:(i + 1) * batch_size, 0].values\n",
        "\n",
        "text_tokens = clip.tokenize([prompt]).cuda()\n",
        "with torch.no_grad():\n",
        "    text_features = model.encode_text(text_tokens).float()\n",
        "best = None, 100\n",
        "search_count = 10000#@param\n",
        "#@markdown *number of molecules to check*\n",
        "for smiles in get_mol_batch():  \n",
        "  s = score(smiles, text_features, dos=dos)\n",
        "  if min(s) < best[1]:\n",
        "    best = smiles[np.argmin(s)], min(s)\n",
        "    IPythonConsole.display.display(Chem.Draw.MolToImage(Chem.MolFromSmiles(best[0])))\n",
        "    print(str(best), search_count, 'remaining')    \n",
        "  search_count -= 1\n",
        "  if search_count <= 0:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}